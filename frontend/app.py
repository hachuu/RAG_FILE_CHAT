# frontend/app.py

import streamlit as st
from rag.loader import load_file, split_text
from rag.vector_store import create_vector_store
from rag.qa_engine import build_qa_chain
from langchain.memory import ConversationBufferMemory
from dotenv import load_dotenv
import os

load_dotenv()
st.set_page_config(page_title="ğŸ“š ë¬¸ì„œ ê¸°ë°˜ ì±—ë´‡", layout="wide")
st.title("ğŸ“‚ ë¬¸ì„œ ì—…ë¡œë“œ â†’ AI ì±—ë´‡")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "qa" not in st.session_state:
    st.session_state.qa = None
if "vectorstore_created" not in st.session_state:
    st.session_state.vectorstore_created = False
if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True
    )

# íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ğŸ“ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (pdf, txt, xlsx, csv)", type=["pdf", "txt", "xlsx", "csv"])

if uploaded_file and not st.session_state.vectorstore_created:
    save_path = f"data/uploads/{uploaded_file.name}"
    with open(save_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    st.success("âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ!")

    # í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ë²¡í„°í™”
    with st.spinner("ğŸ“š ë²¡í„° ìƒì„± ì¤‘..."):
        text = load_file(save_path)
        docs = split_text(text)
        vectorstore = create_vector_store(docs)
        qa = build_qa_chain(vectorstore, st.session_state.memory)
        st.session_state.qa = qa
        st.session_state.vectorstore_created = True
        st.success("âœ… ë¬¸ì„œ ë¶„ì„ ì™„ë£Œ! ì´ì œ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")

# ëŒ€í™” UI
if st.session_state.vectorstore_created:
    with st.form("chat_input_form", clear_on_submit=True):
        user_input = st.text_input("ğŸ’¬ ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”", key="input")
        submitted = st.form_submit_button("ì „ì†¡")

        if submitted and user_input:
            with st.spinner("ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘..."):
                result = st.session_state.qa({"question": user_input})
                st.session_state.chat_history.append(("user", user_input))
                st.session_state.chat_history.append(("ai", result["answer"]))

    # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì¶œë ¥
    for i, (sender, message) in enumerate(st.session_state.chat_history):
        if sender == "user":
            st.markdown(f"ğŸ§‘â€ğŸ’¬ **ë‚˜:** {message}")
        else:
            st.markdown(f"ğŸ¤– **AI:** {message}")

    # ğŸ§  ë¬¸ë§¥ ë””ë²„ê¹…ìš© ì¶œë ¥
    with st.expander("ğŸ§  ëŒ€í™” ë©”ëª¨ë¦¬ ë””ë²„ê¹… ë³´ê¸°"):
        memory = st.session_state.memory
        if memory.buffer:
            for msg in memory.buffer:
                role = "ğŸ‘¤ ì‚¬ìš©ì" if msg.type == "human" else "ğŸ¤– AI"
                st.markdown(f"**{role}:** {msg.content}")
        else:
            st.info("ì•„ì§ ëŒ€í™” ë©”ëª¨ë¦¬ê°€ ë¹„ì–´ ìˆì–´ìš”.")
